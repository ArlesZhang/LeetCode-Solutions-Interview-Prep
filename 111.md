
<div align="center">

<h1>ğŸš€ Algorithmic Engineering: AI Infra & Data Systems</h1>

<strong>A systematic approach to mastering the fundamentals of high-performance systems, data pipelines, and intelligent infrastructure.</strong>

<br/>
<br/>

[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)
[![PRs Welcome](https://img.shields.io/badge/PRs-welcome-brightgreen.svg)](http://makeapullrequest.com)
![C++](https://img.shields.io/badge/c++-%2300599C.svg?style=flat&logo=c%2B%2B&logoColor=white)
![Python](https://img.shields.io/badge/python-3670A0?style=flat&logo=python&logoColor=ffdd54)
![Apache Spark](https://img.shields.io/badge/Apache%20Spark-FDEE21?style=flat&logo=apachespark&logoColor=black)
![LeetCode](https://img.shields.io/badge/LeetCode-000000?style=flat&logo=LeetCode&logoColor=#d16c06)

*"We do not learn algorithms and data structures to pass interviews. We learn them to build the foundations of intelligent systems."*

</div>

---

## ğŸ§­ Navigation

- [ğŸ§­ Navigation](#-navigation)
- [ğŸ¯ Philosophy & Focus](#-philosophy--focus)
- [ğŸ—ï¸ Repository Structure](#ï¸-repository-structure)
- [âš¡ Core Problem Set & Implementation](#-core-problem-set--implementation)
  - [1. C/C++ Focus (AI Infra & Core Systems)](#1-cc-focus-ai-infra--core-systems)
  - [2. Python & Data Engineering Focus](#2-python--data-engineering-focus)
  - [3. Concurrency & Parallelism](#3-concurrency--parallelism)
- [ğŸ—ï¸ System Design & Engineering](#ï¸-system-design--engineering)
  - [Mini-Project: High-Performance LRU Cache](#mini-project-high-performance-lru-cache)
  - [System Design: DataCody Agent](#system-design-datacody-agent)
- [ğŸ“ˆ Progress & Metrics](#-progress--metrics)
- [ğŸš€ Getting Started](#-getting-started)

---

## ğŸ¯ Philosophy & Focus

This repository is not just a collection of solutions. It is a **living portfolio** demonstrating the engineering mindset required for roles in:

*   **AI Infrastructure:** Building low-latency, high-throughput systems for model training and serving.
*   **Intelligent Data Systems (DataCody Agent, FuelGenius):** Designing data pipelines, workflow compilers, and metadata management systems.
*   **Data Platform Engineering:** Creating scalable services for data ingestion, transformation, and analytics.

The code here emphasizes:
*   **Performance & Memory Awareness:** C/C++ solutions that consider cache locality, allocation costs, and Big-O complexity.
*   **Data Scalability:** Python solutions that leverage Pandas for in-memory efficiency and demonstrate distributed thinking (Spark/Hive).
*   **System Reliability:** Robust error handling, comprehensive testing, and clear documentation.
*   **Real-World Applicability:** Connecting algorithmic patterns to their use cases in caching, scheduling, and data processing.

---

## ğŸ—ï¸ Repository Structure

This structure is designed for clarity, scalability, and automation.

```bash
Algorithmic-Engineering/
â”‚
â”œâ”€â”€ README.md                          # Overview + badges + progress board
â”œâ”€â”€ LICENSE
â”œâ”€â”€ .gitignore
â”‚
â”œâ”€â”€ .github/                           # CI/CD & Repo automation
â”‚   â””â”€â”€ workflows/
â”‚       â”œâ”€â”€ cpp_ci.yml                 # C++ tests w/ GTest
â”‚       â”œâ”€â”€ python_ci.yml              # Pytest + Pandas + Spark checks
â”‚       â””â”€â”€ lint.yml                   # Clang-Format & Black
â”‚
â”œâ”€â”€ scripts/                           # DevOps & Productivity
â”‚   â”œâ”€â”€ setup_environment.sh
â”‚   â”œâ”€â”€ run_tests.sh
â”‚   â”œâ”€â”€ generate_stats.py              # Auto-generate problem stats
â”‚   â”œâ”€â”€ sync_readme.py                 # Auto update README progress
â”‚   â””â”€â”€ export_diagrams.sh             # Convert mermaid -> images
â”‚
â”‚
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ core/                          # Your reusable engineering library
â”‚   â”‚   â”œâ”€â”€ cpp/
â”‚   â”‚   â”‚   â”œâ”€â”€ CMakeLists.txt
â”‚   â”‚   â”‚   â”œâ”€â”€ containers/            # Custom DS for interviews & infra
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ lru_cache/
â”‚   â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ include/lru_cache.h
â”‚   â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ src/lru_cache.cpp
â”‚   â”‚   â”‚   â”‚   â”‚   â””â”€â”€ tests/test_lru_cache.cpp
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ ring_buffer/
â”‚   â”‚   â”‚   â”‚   â””â”€â”€ skiplist/
â”‚   â”‚   â”‚   â”œâ”€â”€ concurrency/           # Multi-thread infra-level primitives
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ thread_pool/
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ lock_free_queue/
â”‚   â”‚   â”‚   â”‚   â””â”€â”€ semaphore/
â”‚   â”‚   â”‚   â”œâ”€â”€ graph/                 # Graph engine (for real workload)
â”‚   â”‚   â”‚   â”œâ”€â”€ trees/
â”‚   â”‚   â”‚   â””â”€â”€ utils/
â”‚   â”‚   â””â”€â”€ python/
â”‚   â”‚       â”œâ”€â”€ data_structures/       # DS in Python (heap/tree/utils)
â”‚   â”‚       â”œâ”€â”€ de_utils/
â”‚   â”‚       â”‚   â”œâ”€â”€ spark_utils.py
â”‚   â”‚       â”‚   â”œâ”€â”€ pandas_utils.py
â”‚   â”‚       â”‚   â””â”€â”€ hive_parser.py     # (Optional) Parse Hive outputs
â”‚   â”‚       â””â”€â”€ concurrency/
â”‚
â”‚   â”œâ”€â”€ solutions/                     # LeetCode Engineering Solutions
â”‚   â”‚   â”œâ”€â”€ cpp/
â”‚   â”‚   â”‚   â”œâ”€â”€ 0001-two-sum.cpp
â”‚   â”‚   â”‚   â”œâ”€â”€ 0146-lru-cache.cpp
â”‚   â”‚   â”‚   â”œâ”€â”€ 0295-find-median-from-data-stream.cpp
â”‚   â”‚   â”‚   â”œâ”€â”€ concurrency/           # LC å¤šçº¿ç¨‹é¢˜
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ 1114-print-in-order.cpp
â”‚   â”‚   â”‚   â”‚   â””â”€â”€ 1188-design-bounded-blocking-queue.cpp
â”‚   â”‚   â”‚   â””â”€â”€ â€¦
â”‚   â”‚   â”œâ”€â”€ python/
â”‚   â”‚   â”‚   â”œâ”€â”€ 0001-two-sum.py
â”‚   â”‚   â”‚   â”œâ”€â”€ data_engineering/      # DE + SQL reasoning
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ 0176-second-highest-salary.sql
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ 0185-department-top-three-salaries.sql
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ pandas/
â”‚   â”‚   â”‚   â”‚   â”‚   â””â”€â”€ groupby_transform_cases.py
â”‚   â”‚   â”‚   â”‚   â””â”€â”€ spark/
â”‚   â”‚   â”‚   â”‚       â””â”€â”€ window_functions.py
â”‚   â”‚   â”‚   â””â”€â”€ â€¦
â”‚   â”‚   â”œâ”€â”€ sql/
â”‚   â”‚   â”‚   â”œâ”€â”€ easy/
â”‚   â”‚   â”‚   â”œâ”€â”€ medium/
â”‚   â”‚   â”‚   â””â”€â”€ hard/
â”‚   â”‚   â””â”€â”€ system_design_problems/
â”‚   â”‚       â”œâ”€â”€ tinyurl.md
â”‚   â”‚       â”œâ”€â”€ distributed_queue.md
â”‚   â”‚       â””â”€â”€ data-workflow-compiler.md    # Your signature problem
â”‚
â”‚   â””â”€â”€ system_design/                 # Infra-level thinking
â”‚       â”œâ”€â”€ adr/                       # Architecture Decision Records
â”‚       â”‚   â”œâ”€â”€ 0001-why-thread-pool.md
â”‚       â”‚   â”œâ”€â”€ 0002-cache-layering.md
â”‚       â”‚   â””â”€â”€ 0003-data-pipeline-compiler-core.md
â”‚       â”œâ”€â”€ datacody_agent/
â”‚       â”‚   â”œâ”€â”€ DESIGN.md
â”‚       â”‚   â”œâ”€â”€ diagrams/
â”‚       â”‚   â”‚   â”œâ”€â”€ pipeline-flow.mmd
â”‚       â”‚   â”‚   â””â”€â”€ architecture.png
â”‚       â”‚   â””â”€â”€ prototype/
â”‚       â”‚       â””â”€â”€ mini_compiler_demo.py
â”‚       â””â”€â”€ fuelgenius/
â”‚           â”œâ”€â”€ TRAINING_DATA_SYSTEM.md
â”‚           â””â”€â”€ sampler/
â”‚
â”‚
â”œâ”€â”€ tests/                             # Unified test structure
â”‚   â”œâ”€â”€ cpp/
â”‚   â”‚   â”œâ”€â”€ test_core.cpp
â”‚   â”‚   â””â”€â”€ test_solutions.cpp
â”‚   â”œâ”€â”€ python/
â”‚   â”‚   â”œâ”€â”€ test_pandas.py
â”‚   â”‚   â”œâ”€â”€ test_spark.py
â”‚   â”‚   â””â”€â”€ test_algorithms.py
â”‚   â””â”€â”€ sql/
â”‚       â””â”€â”€ validate_queries.py
â”‚
â”‚
â”œâ”€â”€ docs/                              # Knowledge Base
â”‚   â”œâ”€â”€ cheatsheets/
â”‚   â”‚   â”œâ”€â”€ cpp_stl.md
â”‚   â”‚   â”œâ”€â”€ linux_bash.md
â”‚   â”‚   â”œâ”€â”€ spark_sql.md
â”‚   â”‚   â””â”€â”€ pandas.md
â”‚   â”œâ”€â”€ patterns/
â”‚   â”‚   â”œâ”€â”€ sliding_window.md
â”‚   â”‚   â”œâ”€â”€ monotonic_stack.md
â”‚   â”‚   â””â”€â”€ streaming_pipeline.md
â”‚   â”œâ”€â”€ interview/
â”‚   â”‚   â”œâ”€â”€ ai_infra_100_questions.md
â”‚   â”‚   â”œâ”€â”€ cpp_system_questions.md
â”‚   â”‚   â””â”€â”€ behavioral_star.md
â”‚   â””â”€â”€ articles/
â”‚       â”œâ”€â”€ how-to-think-like-ai-infra-eng.md
â”‚       â””â”€â”€ from-leetcode-to-system-engineer.md
â”‚
â”‚
â””â”€â”€ progress/                          # Growth tracking
    â”œâ”€â”€ solved_log.csv
    â”œâ”€â”€ stats.png
    â”œâ”€â”€ roadmap_90_days.md
    â””â”€â”€ retrospective.md
```

---

## âš¡ Core Problem Set & Implementation

This curated list targets the exact skills needed for your career path.

### 1. C/C++ Focus (AI Infra & Core Systems)

*Problems that involve building complex data structures, managing memory, and achieving O(1) performance.*

| Problem | Title & Link | Key Concepts | Why It Matters |
|:--------|:-------------|:-------------|:---------------|
| **0146** | [LRU Cache](https://leetcode.com/problems/lru-cache/) | Hash Map, Doubly Linked List, O(1) ops | **The canonical caching problem.** Foundational for OS, DBs, and CDNs. |
| **0460** | [LFU Cache](https://leetcode.com/problems/lfu-cache/) | Hash Maps, Balanced Trees, O(1) complexity | Tests deep data structure composition skills. |
| **0295** | [Find Median from Data Stream](https://leetcode.com/problems/find-median-from-data-stream/) | Two Heaps (Min & Max) | Essential for real-time analytics and monitoring systems. |
| **0588** | [Design In-Memory File System](https://leetcode.com/problems/design-in-memory-file-system/) | Trie, OOP Design, API Design | Models hierarchical data, relevant for config systems and metadata stores. |
| **0642** | [Design Search Autocomplete System](https://leetcode.com/problems/design-search-autocomplete-system/) | Trie, Prefix Search, Ranking | Core intelligence for search bars and data discovery tools. |
| **0212** | [Word Search II](https://leetcode.com/problems/word-search-ii/) | Trie, Backtracking, DFS | Pattern matching on a grid; applicable to data validation and parsing. |

### 2. Python & Data Engineering Focus

*Problems that train your data-wrangling, SQL, and distributed processing mindset.*

| Problem | Title & Link | Implementation Focus & Key Concepts |
|:--------|:-------------|:-----------------------------------|
| **0176** | [Second Highest Salary](https://leetcode.com/problems/second-highest-salary/) | **Spark SQL:** `dense_rank()`, `window` functions. **Pandas:** `nlargest`, `drop_duplicates`. Handling NULLs. |
| **0178** | [Rank Scores](https://leetcode.com/problems/rank-scores/) | **Spark SQL:** Window functions (`rank` vs `dense_rank`). **Pandas:** `groupby` and `transform`. |
| **0185** | [Department Top Three Salaries](https://leetcode.com/problems/department-top-three-salaries/) | **Spark SQL:** Correlated subqueries or window functions with partitioning. **Pandas:** `merge`, `groupby`, and complex filtering. |
| **0262** | [Trips and Users](https://leetcode.com/problems/trips-and-users/) | Complex business logic, date-time handling, and conditional aggregation. Represents real-world metric calculation. |
| **0601** | [Human Traffic of Stadium](https://leetcode.com/problems/human-traffic-of-stadium/) | Identifying contiguous sequences. A common pattern in sessionization and event stream processing. |

### 3. Concurrency & Parallelism

*Problems that mirror the scheduling and coordination challenges in distributed data pipelines.*

| Problem | Title & Link | Key Concepts |
|:--------|:-------------|:-------------|
| **1114** | [Print in Order](https://leetcode.com/problems/print-in-order/) | Mutex, Condition Variables. Basic thread sequencing. |
| **1115** | [Print FooBar Alternately](https://leetcode.com/problems/print-foobar-alternately/) | Semaphores. Control interleaved execution of two threads. |
| **1188** | [Design Bounded Blocking Queue](https://leetcode.com/problems/design-bounded-blocking-queue/) | **CRITICAL.** Producer-Consumer pattern. Mutex, Condition Variables. The backbone of data pipelines. |
| **1226** | [The Dining Philosophers](https://leetcode.com/problems/the-dining-philosophers/) | Deadlock prevention, Resource hierarchy. |

---

## ğŸ—ï¸ System Design & Engineering

### Mini-Project: High-Performance LRU Cache

This demonstrates moving from a "solution" to a "component."

**`src/core/cpp/lru_cache/include/lru_cache.h`**
```cpp
#ifndef ALGORITHMIC_ENGINEERING_LRU_CACHE_H
#define ALGORITHMIC_ENGINEERING_LRU_CACHE_H

#include <unordered_map>
#include <list>
#include <mutex> // For thread-safety

namespace core {
    
template <typename K, typename V>
class LRUCache {
public:
    explicit LRUCache(size_t capacity);
    
    // Core API
    bool get(const K& key, V& value);
    void put(const K& key, const V& value);
    
    // Observability for production systems
    size_t size() const;
    double hit_rate() const;
    void clear_stats();

private:
    void evict();
    void promote(typename std::list<std::pair<K, V>>::iterator it);
    
    size_t capacity_;
    std::list<std::pair<K, V>> items_; // (key, value) pairs in access order
    std::unordered_map<K, typename std::list<std::pair<K, V>>::iterator> cache_map_;
    
    // Metrics
    std::atomic<size_t> hits_{0};
    std::atomic<size_t> misses_{0};
    mutable std::mutex mutex_; // For thread-safe access
};

} // namespace core

#endif //ALGORITHMIC_ENGINEERING_LRU_CACHE_H
```
**Key Features:**
*   **Namespace & Include Guards:** Professional C++ structure.
*   **Thread Safety:** Uses `mutex` for concurrent access.
*   **Observability:** Provides `hit_rate()` and other metrics.
*   **Template Design:** Reusable for any key-value type.
*   **Comprehensive Tests:** Unit tests in `tests/` validate correctness under concurrent load.

### System Design: DataCody Agent

**Problem:** Design an intelligent agent that automates dataset profiling, quality checks, and model recommendation.

**Key Discussion Points (Architecture Decision Record - ADR):**

1.  **Service Decomposition:**
    *   **Ingestion Service:** Handles streaming/batch data from S3, Kafka. Built with async Python/Go.
    *   **Profiling Service:** Uses Spark for distributed statistical profiling (mean, std, histogram, null-count).
    *   **Metadata Catalog:** PostgreSQL for structured metadata, Neo4j for data lineage graphs.
    *   **Recommendation Engine:** Lightweight ML model (e.g., Random Forest) that takes dataset stats (num_cols, avg_val, etc.) and suggests a model type (classification, regression).

2.  **Data Flow:**
    ```
    Data Ingest -> (Trigger) -> Spark Profiling Job -> Write Metadata -> Feature Extraction -> Model Recommendation -> Cache Result (Redis)
    ```

3.  **Pipeline Integration:**
    *   The agent is triggered via a webhook from a CI/CD pipeline (e.g., GitLab CI, Airflow DAG) whenever a new dataset version is registered.
    *   Uses a **Bash script** (`scripts/trigger_agent.sh`) as the pipeline entry point, which calls the agent's REST API.

---

## ğŸ“ˆ Progress & Metrics

*   **`progress/solved_log.csv`:** Auto-generated by a Python script that parses your LeetCode submissions.
    ```csv
    date,problem_id,title,difficulty,language,time_taken_minutes,notes
    2023-10-27,146,LRU Cache,Hard,C++,45,Need to review edge case: capacity=0
    ```
*   **`progress/roadmap_90_days.md`:** A phased plan.
    *   **Phase 1 (Days 1-30):** Core DSA & SQL Mastery.
    *   **Phase 2 (Days 31-60):** Concurrency & System Design Deep Dive.
    *   **Phase 3 (Days 61-90):** Integration & Mock Interviews.
*   **`progress/mistakes_retrospective.md`:** A log of errors and lessons learned, fostering a growth mindset.

---

## ğŸš€ Getting Started

1.  **Clone and Setup:**
    ```bash
    git clone https://github.com/yourusername/Algorithmic-Engineering.git
    cd Algorithmic-Engineering
    ./scripts/setup_environment.sh
    ```

2.  **Run Tests:**
    ```bash
    # Run C++ tests
    ./scripts/run_tests.sh cpp
    # Run Python tests
    ./scripts/run_tests.sh python
    ```

3.  **Solve a Problem:**
    *   Create a new file in `src/solutions/` (e.g., `src/solutions/cpp/1234-new-problem.cpp`).
    *   Implement the solution with detailed comments and time/space complexity.
    *   Write corresponding unit tests.
    *   Update the `progress/` logs.

4.  **Contribute:** PRs are welcome for new solutions, optimizations, or documentation improvements.

---

<div align="center">

**This is more than a study guideâ€”it's the foundation of your engineering legacy. Build, learn, and iterate.**

</div>
