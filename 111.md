
<div align="center">

<h1>ğŸš€ Algorithmic Engineering: AI Infra & Data Systems</h1>

<strong>A systematic approach to mastering the fundamentals of high-performance systems, data pipelines, and intelligent infrastructure.</strong>

<br/>
<br/>

[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)
[![PRs Welcome](https://img.shields.io/badge/PRs-welcome-brightgreen.svg)](http://makeapullrequest.com)
![C++](https://img.shields.io/badge/c++-%2300599C.svg?style=flat&logo=c%2B%2B&logoColor=white)
![Python](https://img.shields.io/badge/python-3670A0?style=flat&logo=python&logoColor=ffdd54)
![Apache Spark](https://img.shields.io/badge/Apache%20Spark-FDEE21?style=flat&logo=apachespark&logoColor=black)
![LeetCode](https://img.shields.io/badge/LeetCode-000000?style=flat&logo=LeetCode&logoColor=#d16c06)

*"We do not learn algorithms and data structures to pass interviews. We learn them to build the foundations of intelligent systems."*

</div>

---

## ğŸ§­ Navigation

- [ğŸ§­ Navigation](#-navigation)
- [ğŸ¯ Philosophy & Focus](#-philosophy--focus)
- [ğŸ—ï¸ Repository Structure](#ï¸-repository-structure)
- [âš¡ Core Problem Set & Implementation](#-core-problem-set--implementation)
  - [1. C/C++ Focus (AI Infra & Core Systems)](#1-cc-focus-ai-infra--core-systems)
  - [2. Python & Data Engineering Focus](#2-python--data-engineering-focus)
  - [3. Concurrency & Parallelism](#3-concurrency--parallelism)
- [ğŸ—ï¸ System Design & Engineering](#ï¸-system-design--engineering)
  - [Mini-Project: High-Performance LRU Cache](#mini-project-high-performance-lru-cache)
  - [System Design: DataCody Agent](#system-design-datacody-agent)
- [ğŸ“ˆ Progress & Metrics](#-progress--metrics)
- [ğŸš€ Getting Started](#-getting-started)

---

## ğŸ¯ Philosophy & Focus

This repository documents my journey in mastering Data Structures, Algorithms, and System Design principles. The focus is on building a strong foundation for roles in **AI Infrastructure**, **Data-Intelligent Systems**, and **High-Performance Data Engineering**.

**Key Focus Areas:**
*   **Performance-Critical Systems:** C/C++ implementations focusing on memory management and low-latency.
*   **Large-Scale Data Processing:** Python solutions leveraging Pandas, PySpark SQL, and understanding of distributed systems.
*   **System Automation & DevOps:** Scripts and pipelines for automation (Linux Bash, Pipeline tools).
*   **API & System Design:** Architecting scalable and robust systems.

---

## ğŸ—ï¸ Repository Structure

```
LeetCode-Solutions-Interview-Prep/
â”‚
â”œâ”€â”€ README.md                          # This file
â”œâ”€â”€ .github/workflows/                 # CI/CD for running tests
â”‚   â”œâ”€â”€ cpp_ci.yml
â”‚   â”œâ”€â”€ python_ci.yml
â”‚   â””â”€â”€ lint.yml
â”œâ”€â”€ scripts/                           # Utility scripts
â”‚   â”œâ”€â”€ run_tests.sh
â”‚   â”œâ”€â”€ setup_environment.sh
â”‚   â”œâ”€â”€ generate_stats.py
â”‚   â”œâ”€â”€ sync_readme.py
â”‚   â””â”€â”€ export_diagrams.sh
â”‚
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ core/                          # Reusable engineering components
â”‚   â”‚   â”œâ”€â”€ cpp/
â”‚   â”‚   â”‚   â”œâ”€â”€ CMakeLists.txt
â”‚   â”‚   â”‚   â”œâ”€â”€ containers/
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ lru_cache/
â”‚   â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ include/lru_cache.h
â”‚   â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ src/lru_cache.cpp
â”‚   â”‚   â”‚   â”‚   â”‚   â””â”€â”€ tests/test_lru_cache.cpp
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ ring_buffer/
â”‚   â”‚   â”‚   â”‚   â””â”€â”€ skiplist/
â”‚   â”‚   â”‚   â”œâ”€â”€ concurrency/
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ thread_pool/
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ lock_free_queue/
â”‚   â”‚   â”‚   â”‚   â””â”€â”€ semaphore/
â”‚   â”‚   â”‚   â”œâ”€â”€ graph/
â”‚   â”‚   â”‚   â”œâ”€â”€ trees/
â”‚   â”‚   â”‚   â””â”€â”€ utils/
â”‚   â”‚   â””â”€â”€ python/
â”‚   â”‚       â”œâ”€â”€ data_structures/
â”‚   â”‚       â”œâ”€â”€ de_utils/
â”‚   â”‚       â”‚   â”œâ”€â”€ spark_utils.py
â”‚   â”‚       â”‚   â”œâ”€â”€ pandas_utils.py
â”‚   â”‚       â”‚   â””â”€â”€ hive_parser.py
â”‚   â”‚       â””â”€â”€ concurrency/
â”‚   â”‚
â”‚   â”œâ”€â”€ solutions/                     # LeetCode solutions
â”‚   â”‚   â”œâ”€â”€ cpp/
â”‚   â”‚   â”‚   â”œâ”€â”€ 0001-two-sum.cpp
â”‚   â”‚   â”‚   â”œâ”€â”€ 0146-lru-cache.cpp
â”‚   â”‚   â”‚   â”œâ”€â”€ 0295-find-median-from-data-stream.cpp
â”‚   â”‚   â”‚   â””â”€â”€ concurrency/
â”‚   â”‚   â”‚       â”œâ”€â”€ 1114-print-in-order.cpp
â”‚   â”‚   â”‚       â””â”€â”€ 1188-design-bounded-blocking-queue.cpp
â”‚   â”‚   â”œâ”€â”€ python/
â”‚   â”‚   â”‚   â”œâ”€â”€ 0001-two-sum.py
â”‚   â”‚   â”‚   â””â”€â”€ data_engineering/
â”‚   â”‚   â”‚       â”œâ”€â”€ 0176-second-highest-salary.sql
â”‚   â”‚   â”‚       â”œâ”€â”€ 0185-department-top-three-salaries.sql
â”‚   â”‚   â”‚       â”œâ”€â”€ pandas/
â”‚   â”‚   â”‚       â”‚   â””â”€â”€ groupby_transform_cases.py
â”‚   â”‚   â”‚       â””â”€â”€ spark/
â”‚   â”‚   â”‚           â””â”€â”€ window_functions.py
â”‚   â”‚   â”œâ”€â”€ sql/
â”‚   â”‚   â”‚   â”œâ”€â”€ easy/
â”‚   â”‚   â”‚   â”‚   â””â”€â”€ 0175-combine-two-tables.sql
â”‚   â”‚   â”‚   â”œâ”€â”€ medium/
â”‚   â”‚   â”‚   â”‚   â””â”€â”€ 0176-second-highest-salary.sql
â”‚   â”‚   â”‚   â””â”€â”€ hard/
â”‚   â”‚   â”‚       â””â”€â”€ 0185-department-top-three-salaries.sql
â”‚   â”‚   â””â”€â”€ system_design_problems/
â”‚   â”‚       â”œâ”€â”€ tinyurl.md
â”‚   â”‚       â”œâ”€â”€ distributed_queue.md
â”‚   â”‚       â””â”€â”€ data-workflow-compiler.md
â”‚   â”‚
â”‚   â””â”€â”€ system_design/                 # System design preparations
â”‚       â”œâ”€â”€ adr/
â”‚       â”‚   â”œâ”€â”€ 0001-why-thread-pool.md
â”‚       â”‚   â”œâ”€â”€ 0002-cache-layering.md
â”‚       â”‚   â””â”€â”€ 0003-data-pipeline-compiler-core.md
â”‚       â”œâ”€â”€ datacody_agent/
â”‚       â”‚   â”œâ”€â”€ DESIGN.md
â”‚       â”‚   â”œâ”€â”€ diagrams/
â”‚       â”‚   â”‚   â””â”€â”€ pipeline-flow.mmd
â”‚       â”‚   â””â”€â”€ prototype/
â”‚       â”‚       â””â”€â”€ mini_compiler_demo.py
â”‚       â””â”€â”€ fuelgenius/
â”‚           â”œâ”€â”€ TRAINING_DATA_SYSTEM.md
â”‚           â””â”€â”€ sampler/
â”‚               â””â”€â”€ data_sampler.py
â”‚
â”œâ”€â”€ tests/                             # Test suites
â”‚   â”œâ”€â”€ cpp/
â”‚   â”‚   â”œâ”€â”€ test_core.cpp
â”‚   â”‚   â””â”€â”€ test_solutions.cpp
â”‚   â”œâ”€â”€ python/
â”‚   â”‚   â”œâ”€â”€ test_pandas.py
â”‚   â”‚   â”œâ”€â”€ test_spark.py
â”‚   â”‚   â””â”€â”€ test_algorithms.py
â”‚   â””â”€â”€ sql/
â”‚       â””â”€â”€ validate_queries.py
â”‚
â”œâ”€â”€ docs/                              # Knowledge base
â”‚   â”œâ”€â”€ cheatsheets/
â”‚   â”‚   â”œâ”€â”€ cpp_stl.md
â”‚   â”‚   â”œâ”€â”€ linux_bash.md
â”‚   â”‚   â”œâ”€â”€ spark_sql.md
â”‚   â”‚   â””â”€â”€ pandas.md
â”‚   â”œâ”€â”€ patterns/
â”‚   â”‚   â”œâ”€â”€ sliding_window.md
â”‚   â”‚   â”œâ”€â”€ monotonic_stack.md
â”‚   â”‚   â””â”€â”€ streaming_pipeline.md
â”‚   â”œâ”€â”€ interview/
â”‚   â”‚   â”œâ”€â”€ ai_infra_100_questions.md
â”‚   â”‚   â”œâ”€â”€ cpp_system_questions.md
â”‚   â”‚   â””â”€â”€ behavioral_star.md
â”‚   â””â”€â”€ articles/
â”‚       â”œâ”€â”€ how-to-think-like-ai-infra-eng.md
â”‚       â””â”€â”€ from-leetcode-to-system-engineer.md
â”‚
â””â”€â”€ progress/                          # Progress tracking
    â”œâ”€â”€ solved_log.csv
    â”œâ”€â”€ roadmap_90_days.md
    â””â”€â”€ retrospective.md
```

---

## âš¡ Core Problem Set & Implementation

### 1. C/C++ Focus (AI Infra & Core Systems)

| Problem | Title & Link | Key Concepts | Why It Matters |
|:--------|:-------------|:-------------|:---------------|
| **0146** | [LRU Cache](https://leetcode.com/problems/lru-cache/) | Hash Map, Doubly Linked List, O(1) ops | **Fundamental for caching** in OS, databases, and infra. |
| **0460** | [LFU Cache](https://leetcode.com/problems/lfu-cache/) | Hash Maps, Balanced Trees, O(1) complexity | Tests deep data structure composition skills. |
| **0295** | [Find Median from Data Stream](https://leetcode.com/problems/find-median-from-data-stream/) | Two Heaps (Min & Max) | Essential for real-time analytics and monitoring systems. |
| **0588** | [Design In-Memory File System](https://leetcode.com/problems/design-in-memory-file-system/) | Trie, OOP Design, API Design | Models hierarchical data, relevant for config systems and metadata stores. |
| **0239** | [Sliding Window Maximum](https://leetcode.com/problems/sliding-window-maximum/) | Deque, Monotonic Queue | Common pattern in data streams and network processing. |
| **0642** | [Design Search Autocomplete System](https://leetcode.com/problems/design-search-autocomplete-system/) | Trie, Prefix Search, Ranking | Core intelligence for search bars and data discovery tools. |
| **0212** | [Word Search II](https://leetcode.com/problems/word-search-ii/) | Trie, Backtracking, DFS | Pattern matching for data validation and parsing. |

### 2. Python & Data Engineering Focus

*Problems that train your data-wrangling, SQL, and distributed processing mindset.*

| Problem | Title & Link | Implementation Focus & Key Concepts |
|:--------|:-------------|:-----------------------------------|
| **0176** | [Second Highest Salary](https://leetcode.com/problems/second-highest-salary/) | **Spark SQL:** `dense_rank()`, `window` functions. **Pandas:** `nlargest`, `drop_duplicates`. Handling NULLs. |
| **0178** | [Rank Scores](https://leetcode.com/problems/rank-scores/) | **Spark SQL:** Window functions (`rank` vs `dense_rank`). **Pandas:** `groupby` and `transform`. |
| **0185** | [Department Top Three Salaries](https://leetcode.com/problems/department-top-three-salaries/) | **Spark SQL:** Correlated subqueries or window functions with partitioning. **Pandas:** `merge`, `groupby`, and complex filtering. |
| **0262** | [Trips and Users](https://leetcode.com/problems/trips-and-users/) | Complex business logic, date-time handling, and conditional aggregation. Represents real-world metric calculation. |
| **0601** | [Human Traffic of Stadium](https://leetcode.com/problems/human-traffic-of-stadium/) | Identifying contiguous sequences. A common pattern in sessionization and event stream processing. |

### 3. Concurrency & Parallelism

| Problem | Title & Link | Key Concepts |
|:--------|:-------------|:-------------|
| **1114** | [Print in Order](https://leetcode.com/problems/print-in-order/) | Mutex, Condition Variables |
| **1115** | [Print FooBar Alternately](https://leetcode.com/problems/print-foobar-alternately/) | Semaphores. Control interleaved execution of two threads. |
| **1188** | [Design Bounded Blocking Queue](https://leetcode.com/problems/design-bounded-blocking-queue/) | Producer-Consumer pattern, Mutex, Condition Variables |
| **1226** | [The Dining Philosophers](https://leetcode.com/problems/the-dining-philosophers/) | Deadlock prevention, Resource hierarchy |

---

## ğŸ—ï¸ System Design & Engineering

### Mini-Project: High-Performance LRU Cache

**Location**: `src/core/cpp/containers/lru_cache/include/lru_cache.h`

```cpp
#ifndef ALGORITHMIC_ENGINEERING_LRU_CACHE_H
#define ALGORITHMIC_ENGINEERING_LRU_CACHE_H

#include <unordered_map>
#include <list>
#include <mutex>

namespace core {
    
template <typename K, typename V>
class LRUCache {
public:
    explicit LRUCache(size_t capacity);
    
    // Core API
    bool get(const K& key, V& value);
    void put(const K& key, const V& value);
    
    // Observability
    size_t size() const;
    double hit_rate() const;

private:
    void evict();
    
    size_t capacity_;
    std::list<std::pair<K, V>> items_;
    std::unordered_map<K, typename std::list<std::pair<K, V>>::iterator> cache_map_;
    
    std::atomic<size_t> hits_{0};
    std::atomic<size_t> misses_{0};
    mutable std::mutex mutex_;
};

} // namespace core

#endif
```

### System Design: DataCody Agent

**Problem:** Design an intelligent agent ("DataCody") that can profile datasets, suggest quality checks, and recommend suitable ML models.

**Key Discussion Points:**
1.  **Service Architecture:** Microservices vs Monolith. API design (REST/gRPC).
2.  **Data Ingestion & Profiling:** Handling large datasets with Spark for distributed profiling.
3.  **Metadata Storage:** PostgreSQL for structured metadata, Neo4j for data lineage.
4.  **Model Recommendation Engine:** ML service that takes dataset stats and suggests model types.
5.  **Pipeline Integration:** CI/CD pipeline triggers via webhooks.

---

## ğŸ“ˆ Progress & Metrics

*   **`progress/solved_log.csv`:** Auto-generated progress tracking
    ```csv
    date,problem_id,title,difficulty,language,time_taken_minutes,notes
    2024-11-26,146,LRU Cache,Hard,C++,45,Implement thread-safe version
    ```
*   **`progress/roadmap_90_days.md`:** Phased learning plan
*   **`progress/retrospective.md`:** Lessons learned and improvements

---

## ğŸš€ Getting Started

1.  **Clone and Setup:**
    ```bash
    git clone git@github.com:ArlesZhang/LeetCode-Solutions-Interview-Prep.git
    cd LeetCode-Solutions-Interview-Prep
    ```

2.  **Solve Problems Systematically:**
    ```bash
    # Create solution file
    vim src/solutions/cpp/0001-two-sum.cpp
    
    # Write tests
    vim tests/cpp/test_solutions.cpp
    
    # Update progress
    python scripts/generate_stats.py
    ```

3.  **Run Tests:**
    ```bash
    ./scripts/run_tests.sh cpp
    ./scripts/run_tests.sh python
    ```

4.  **Commit and Push:**
    ```bash
    git add .
    git commit -m "feat: solve PROBLEM_ID with APPROACH"
    git push origin main
    ```

---

<div align="center">

**This is more than a study guideâ€”it's the foundation of your engineering legacy. Build, learn, and iterate.**

</div>


