
<div align="center">

<h1>ğŸš€ Algorithmic Engineering: AI Infra & Data Systems</h1>

<strong>A systematic approach to mastering the fundamentals of high-performance systems, data pipelines, and intelligent infrastructure.</strong>

<br/>
<br/>

[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)
[![PRs Welcome](https://img.shields.io/badge/PRs-welcome-brightgreen.svg)](http://makeapullrequest.com)
![C++](https://img.shields.io/badge/c++-%2300599C.svg?style=flat&logo=c%2B%2B&logoColor=white)
![Python](https://img.shields.io/badge/python-3670A0?style=flat&logo=python&logoColor=ffdd54)
![Apache Spark](https://img.shields.io/badge/Apache%20Spark-FDEE21?style=flat&logo=apachespark&logoColor=black)
![LeetCode](https://img.shields.io/badge/LeetCode-000000?style=flat&logo=LeetCode&logoColor=#d16c06)

*"We do not learn algorithms and data structures to pass interviews. We learn them to build the foundations of intelligent systems."*

</div>

---

## Navigation

- [ğŸ§­ Navigation](#-navigation)
- [ğŸ¯ Philosophy & Focus](#-philosophy--focus)
- [ğŸ—ï¸ Repository Structure](#ï¸-repository-structure)
- [âš¡ Core Problem Set & Implementation](#-core-problem-set--implementation)
  - [1. C/C++ Focus (AI Infra & Core Systems)](#1-cc-focus-ai-infra--core-systems)
  - [2. Python & Data Engineering Focus](#2-python--data-engineering-focus)
  - [3. Concurrency & Parallelism](#3-concurrency--parallelism)
- [ğŸ—ï¸ System Design & Engineering](#ï¸-system-design--engineering)
  - [Mini-Project: High-Performance LRU Cache](#mini-project-high-performance-lru-cache)
  - [System Design: DataCody Agent](#system-design-datacody-agent)
- [ğŸ“ˆ Progress & Metrics](#-progress--metrics)
- [ğŸš€ Getting Started](#-getting-started)

---

## Philosophy & Focus

This repository documents my journey in mastering Data Structures, Algorithms, and System Design principles. The focus is on building a strong foundation for roles in **AI Infrastructure**, **Data-Intelligent Systems**, and **High-Performance Data Engineering**.

**Key Focus Areas:**
*   **Performance-Critical Systems:** C/C++ implementations focusing on memory management and low-latency.
*   **Large-Scale Data Processing:** Python solutions leveraging Pandas, PySpark SQL, and understanding of distributed systems.
*   **System Automation & DevOps:** Scripts and pipelines for automation (Linux Bash, Pipeline tools).
*   **API & System Design:** Architecting scalable and robust systems.

---

## Repository Structure

```
LeetCode-Solutions-Interview-Prep/
â”œâ”€â”€ ğŸ“š docs/                           # çŸ¥è¯†åº“æ–‡æ¡£
â”‚   â”œâ”€â”€ articles/                      # æŠ€æœ¯æ–‡ç« å’Œæ·±åº¦æ€è€ƒ
â”‚   â”‚   â”œâ”€â”€ from-leetcode-to-system-engineer.md    # èŒä¸šå‘å±•è·¯å¾„
â”‚   â”‚   â””â”€â”€ how-to-think-like-ai-infra-eng.md      # AIåŸºç¡€è®¾æ–½æ€ç»´æ¨¡å¼
â”‚   â”œâ”€â”€ cheatsheets/                   # é€ŸæŸ¥æ‰‹å†Œ
â”‚   â”‚   â”œâ”€â”€ cpp_stl.md                 # C++æ ‡å‡†åº“å¿«é€Ÿå‚è€ƒ
â”‚   â”‚   â”œâ”€â”€ linux_bash.md              # Linuxå‘½ä»¤å’Œè„šæœ¬æŠ€å·§
â”‚   â”‚   â”œâ”€â”€ pandas.md                  # Pandasæ•°æ®å¤„ç†å¤‡å¿˜
â”‚   â”‚   â””â”€â”€ spark_sql.md               # Spark SQLè¯­æ³•å’Œä¼˜åŒ–
â”‚   â”œâ”€â”€ interview/                     # é¢è¯•å‡†å¤‡èµ„æ–™
â”‚   â”‚   â”œâ”€â”€ ai_infra_100_questions.md  # AIåŸºç¡€è®¾æ–½é¢è¯•é¢˜
â”‚   â”‚   â”œâ”€â”€ behavioral_star.md         # è¡Œä¸ºé¢è¯•STARæ–¹æ³•
â”‚   â”‚   â””â”€â”€ cpp_system_questions.md    # C++ç³»ç»Ÿçº§å¼€å‘é—®é¢˜
â”‚   â””â”€â”€ patterns/                      # ç®—æ³•å’Œç³»ç»Ÿæ¨¡å¼
â”‚       â”œâ”€â”€ monotonic_stack.md         # å•è°ƒæ ˆæ¨¡å¼åŠåº”ç”¨
â”‚       â”œâ”€â”€ sliding_window.md          # æ»‘åŠ¨çª—å£æ¨¡å¼
â”‚       â””â”€â”€ streaming_pipeline.md      # æµå¼å¤„ç†ç®¡é“è®¾è®¡
â”‚
â”œâ”€â”€ âš–ï¸ LICENSE                         # å¼€æºè®¸å¯è¯
â”œâ”€â”€ ğŸ“ˆ progress/                       # å­¦ä¹ è¿›åº¦è·Ÿè¸ª
â”‚   â”œâ”€â”€ retrospective.md               # å­¦ä¹ å›é¡¾å’Œåæ€
â”‚   â”œâ”€â”€ roadmap_90_days.md             # 90å¤©å­¦ä¹ è·¯çº¿å›¾
â”‚   â””â”€â”€ solved_log.csv                 # è§£é¢˜è®°å½•ç»Ÿè®¡
â”‚
â”œâ”€â”€ ğŸ“– README.md                       # é¡¹ç›®ä¸»æ–‡æ¡£
â”œâ”€â”€ âš™ï¸ scripts/                        # è‡ªåŠ¨åŒ–è„šæœ¬
â”‚   â”œâ”€â”€ export_diagrams.sh             # å¯¼å‡ºæ¶æ„å›¾
â”‚   â”œâ”€â”€ generate_stats.py              # ç”Ÿæˆå­¦ä¹ ç»Ÿè®¡æ•°æ®
â”‚   â”œâ”€â”€ run_tests.sh                   # è¿è¡Œæµ‹è¯•å¥—ä»¶
â”‚   â”œâ”€â”€ setup_environment.sh           # ç¯å¢ƒé…ç½®è„šæœ¬
â”‚   â””â”€â”€ sync_readme.py                 # åŒæ­¥READMEè¿›åº¦
â”‚
â”œâ”€â”€ ğŸ’» src/                            # æºä»£ç æ ¸å¿ƒ
â”‚   â”œâ”€â”€ ğŸ”§ core/                       # å¯å¤ç”¨å·¥ç¨‹ç»„ä»¶åº“
â”‚   â”‚   â”œâ”€â”€ cpp/                       # C++é«˜æ€§èƒ½ç»„ä»¶
â”‚   â”‚   â”‚   â”œâ”€â”€ CMakeLists.txt         # C++é¡¹ç›®æ„å»ºé…ç½®
â”‚   â”‚   â”‚   â”œâ”€â”€ concurrency/           # å¹¶å‘ç¼–ç¨‹åŸè¯­
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ lock_free_queue/   # æ— é”é˜Ÿåˆ—å®ç°
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ semaphore/         # ä¿¡å·é‡åŒæ­¥
â”‚   â”‚   â”‚   â”‚   â””â”€â”€ thread_pool/       # çº¿ç¨‹æ± ç®¡ç†
â”‚   â”‚   â”‚   â”œâ”€â”€ containers/            # è‡ªå®šä¹‰æ•°æ®ç»“æ„
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ lru_cache/         # LRUç¼“å­˜å®ç°
â”‚   â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ include/lru_cache.h        # å¤´æ–‡ä»¶
â”‚   â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ src/lru_cache.cpp          # å®ç°æ–‡ä»¶
â”‚   â”‚   â”‚   â”‚   â”‚   â””â”€â”€ tests/test_lru_cache.cpp   # å•å…ƒæµ‹è¯•
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ ring_buffer/       # ç¯å½¢ç¼“å†²åŒº
â”‚   â”‚   â”‚   â”‚   â””â”€â”€ skiplist/          # è·³è¡¨æ•°æ®ç»“æ„
â”‚   â”‚   â”‚   â”œâ”€â”€ graph/                 # å›¾ç®—æ³•å¼•æ“
â”‚   â”‚   â”‚   â”œâ”€â”€ trees/                 # æ ‘ç»“æ„å’Œç®—æ³•
â”‚   â”‚   â”‚   â””â”€â”€ utils/                 # å·¥å…·å‡½æ•°
â”‚   â”‚   â””â”€â”€ python/                    # Pythonæ•°æ®å·¥ç¨‹å·¥å…·
â”‚   â”‚       â”œâ”€â”€ concurrency/           # Pythonå¹¶å‘ç¼–ç¨‹
â”‚   â”‚       â”œâ”€â”€ data_structures/       # Pythonæ•°æ®ç»“æ„å®ç°
â”‚   â”‚       â””â”€â”€ de_utils/              # æ•°æ®å·¥ç¨‹å·¥å…·é›†
â”‚   â”‚           â”œâ”€â”€ hive_parser.py     # HiveæŸ¥è¯¢è§£æå™¨
â”‚   â”‚           â”œâ”€â”€ pandas_utils.py    # Pandaså·¥å…·å‡½æ•°
â”‚   â”‚           â””â”€â”€ spark_utils.py     # Sparkä¼šè¯ç®¡ç†
â”‚   â”‚
â”‚   â”œâ”€â”€ ğŸ¯ solutions/                  # LeetCodeè§£å†³æ–¹æ¡ˆ
â”‚   â”‚   â”œâ”€â”€ cpp/                       # C++ç®—æ³•å®ç°
â”‚   â”‚   â”‚   â”œâ”€â”€ 0001-two-sum.cpp       # ä¸¤æ•°ä¹‹å’Œ
â”‚   â”‚   â”‚   â”œâ”€â”€ 0146-lru-cache.cpp     # LRUç¼“å­˜è®¾è®¡
â”‚   â”‚   â”‚   â”œâ”€â”€ 0295-find-median-from-data-stream.cpp  # æ•°æ®æµä¸­ä½æ•°
â”‚   â”‚   â”‚   â””â”€â”€ concurrency/           # å¹¶å‘ç¼–ç¨‹é¢˜ç›®
â”‚   â”‚   â”‚       â”œâ”€â”€ 1114-print-in-order.cpp          # é¡ºåºæ‰“å°
â”‚   â”‚   â”‚       â””â”€â”€ 1188-design-bounded-blocking-queue.cpp  # é˜»å¡é˜Ÿåˆ—
â”‚   â”‚   â”œâ”€â”€ python/                    # Pythonè§£å†³æ–¹æ¡ˆ
â”‚   â”‚   â”‚   â”œâ”€â”€ 0001-two-sum.py        # Pythonç‰ˆä¸¤æ•°ä¹‹å’Œ
â”‚   â”‚   â”‚   â””â”€â”€ data_engineering/      # æ•°æ®å·¥ç¨‹é¢˜ç›®
â”‚   â”‚   â”‚       â”œâ”€â”€ 0176-second-highest-salary.sql    # ç¬¬äºŒé«˜è–ªæ°´
â”‚   â”‚   â”‚       â”œâ”€â”€ 0185-department-top-three-salaries.sql  # éƒ¨é—¨å‰ä¸‰è–ªæ°´
â”‚   â”‚   â”‚       â”œâ”€â”€ pandas/            # Pandasæ•°æ®å¤„ç†
â”‚   â”‚   â”‚       â”‚   â””â”€â”€ groupby_transform_cases.py    # åˆ†ç»„è½¬æ¢æ¡ˆä¾‹
â”‚   â”‚   â”‚       â””â”€â”€ spark/             # Sparkå¤„ç†æ¨¡å¼
â”‚   â”‚   â”‚           â””â”€â”€ window_functions.py           # çª—å£å‡½æ•°åº”ç”¨
â”‚   â”‚   â”œâ”€â”€ sql/                       # SQLä¸“é¡¹ç»ƒä¹ 
â”‚   â”‚   â”‚   â”œâ”€â”€ easy/                  # ç®€å•éš¾åº¦
â”‚   â”‚   â”‚   â”‚   â””â”€â”€ 0175-combine-two-tables.sql       # åˆå¹¶ä¸¤è¡¨
â”‚   â”‚   â”‚   â”œâ”€â”€ hard/                  # å›°éš¾éš¾åº¦
â”‚   â”‚   â”‚   â”‚   â””â”€â”€ 0185-department-top-three-salaries.sql  # éƒ¨é—¨å‰ä¸‰
â”‚   â”‚   â”‚   â””â”€â”€ medium/                # ä¸­ç­‰éš¾åº¦
â”‚   â”‚   â”‚       â””â”€â”€ 0176-second-highest-salary.sql    # ç¬¬äºŒé«˜è–ªæ°´
â”‚   â”‚   â””â”€â”€ system_design_problems/    # ç³»ç»Ÿè®¾è®¡é¢˜ç›®
â”‚   â”‚       â”œâ”€â”€ data-workflow-compiler.md     # æ•°æ®å·¥ä½œæµç¼–è¯‘å™¨è®¾è®¡
â”‚   â”‚       â”œâ”€â”€ distributed_queue.md          # åˆ†å¸ƒå¼é˜Ÿåˆ—è®¾è®¡
â”‚   â”‚       â””â”€â”€ tinyurl.md                    # çŸ­é“¾æ¥ç³»ç»Ÿè®¾è®¡
â”‚   â”‚
â”‚   â””â”€â”€ ğŸ—ï¸ system_design/              # ç³»ç»Ÿæ¶æ„è®¾è®¡
â”‚       â”œâ”€â”€ adr/                       # æ¶æ„å†³ç­–è®°å½•
â”‚       â”‚   â”œâ”€â”€ 0001-why-thread-pool.md        # çº¿ç¨‹æ± é€‰æ‹©åŸå› 
â”‚       â”‚   â”œâ”€â”€ 0002-cache-layering.md         # ç¼“å­˜åˆ†å±‚è®¾è®¡
â”‚       â”‚   â””â”€â”€ 0003-data-pipeline-compiler-core.md  # æ•°æ®ç®¡é“ç¼–è¯‘å™¨æ ¸å¿ƒ
â”‚       â”œâ”€â”€ datacody_agent/            # DataCodyæ™ºèƒ½ä»£ç†è®¾è®¡
â”‚       â”‚   â”œâ”€â”€ DESIGN.md              # æ•´ä½“æ¶æ„è®¾è®¡æ–‡æ¡£
â”‚       â”‚   â”œâ”€â”€ diagrams/              # æ¶æ„å›¾
â”‚       â”‚   â”‚   â””â”€â”€ pipeline-flow.mmd  # ç®¡é“æµç¨‹å›¾
â”‚       â”‚   â””â”€â”€ prototype/             # åŸå‹å®ç°
â”‚       â”‚       â””â”€â”€ mini_compiler_demo.py      # è¿·ä½ ç¼–è¯‘å™¨æ¼”ç¤º
â”‚       â””â”€â”€ fuelgenius/                # FuelGeniusé¡¹ç›®è®¾è®¡
â”‚           â”œâ”€â”€ sampler/               # æ•°æ®é‡‡æ ·å™¨
â”‚           â”‚   â””â”€â”€ data_sampler.py    # æ•°æ®é‡‡æ ·å®ç°
â”‚           â””â”€â”€ TRAINING_DATA_SYSTEM.md        # è®­ç»ƒæ•°æ®ç³»ç»Ÿè®¾è®¡
â”‚
â””â”€â”€ âœ… tests/                          # æµ‹è¯•å¥—ä»¶
    â”œâ”€â”€ cpp/                           # C++æµ‹è¯•
    â”‚   â”œâ”€â”€ test_core.cpp              # æ ¸å¿ƒç»„ä»¶æµ‹è¯•
    â”‚   â””â”€â”€ test_solutions.cpp         # è§£å†³æ–¹æ¡ˆæµ‹è¯•
    â”œâ”€â”€ python/                        # Pythonæµ‹è¯•
    â”‚   â”œâ”€â”€ test_algorithms.py         # ç®—æ³•æµ‹è¯•
    â”‚   â”œâ”€â”€ test_pandas.py             # PandasåŠŸèƒ½æµ‹è¯•
    â”‚   â””â”€â”€ test_spark.py              # SparkåŠŸèƒ½æµ‹è¯•
    â””â”€â”€ sql/                           # SQLæµ‹è¯•
        â””â”€â”€ validate_queries.py        # æŸ¥è¯¢éªŒè¯æµ‹è¯•
```

---

## Core Problem Set & Implementation

### 1. C/C++ Focus (AI Infra & Core Systems)

| Problem | Title & Link | Key Concepts | Why It Matters |
|:--------|:-------------|:-------------|:---------------|
| **0146** | [LRU Cache](https://leetcode.com/problems/lru-cache/) | Hash Map, Doubly Linked List, O(1) ops | **Fundamental for caching** in OS, databases, and infra. |
| **0460** | [LFU Cache](https://leetcode.com/problems/lfu-cache/) | Hash Maps, Balanced Trees, O(1) complexity | Tests deep data structure composition skills. |
| **0295** | [Find Median from Data Stream](https://leetcode.com/problems/find-median-from-data-stream/) | Two Heaps (Min & Max) | Essential for real-time analytics and monitoring systems. |
| **0588** | [Design In-Memory File System](https://leetcode.com/problems/design-in-memory-file-system/) | Trie, OOP Design, API Design | Models hierarchical data, relevant for config systems and metadata stores. |
| **0239** | [Sliding Window Maximum](https://leetcode.com/problems/sliding-window-maximum/) | Deque, Monotonic Queue | Common pattern in data streams and network processing. |
| **0642** | [Design Search Autocomplete System](https://leetcode.com/problems/design-search-autocomplete-system/) | Trie, Prefix Search, Ranking | Core intelligence for search bars and data discovery tools. |
| **0212** | [Word Search II](https://leetcode.com/problems/word-search-ii/) | Trie, Backtracking, DFS | Pattern matching for data validation and parsing. |

### 2. Python & Data Engineering Focus

*Problems that train your data-wrangling, SQL, and distributed processing mindset.*

| Problem | Title & Link | Implementation Focus & Key Concepts |
|:--------|:-------------|:-----------------------------------|
| **0176** | [Second Highest Salary](https://leetcode.com/problems/second-highest-salary/) | **Spark SQL:** `dense_rank()`, `window` functions. **Pandas:** `nlargest`, `drop_duplicates`. Handling NULLs. |
| **0178** | [Rank Scores](https://leetcode.com/problems/rank-scores/) | **Spark SQL:** Window functions (`rank` vs `dense_rank`). **Pandas:** `groupby` and `transform`. |
| **0185** | [Department Top Three Salaries](https://leetcode.com/problems/department-top-three-salaries/) | **Spark SQL:** Correlated subqueries or window functions with partitioning. **Pandas:** `merge`, `groupby`, and complex filtering. |
| **0262** | [Trips and Users](https://leetcode.com/problems/trips-and-users/) | Complex business logic, date-time handling, and conditional aggregation. Represents real-world metric calculation. |
| **0601** | [Human Traffic of Stadium](https://leetcode.com/problems/human-traffic-of-stadium/) | Identifying contiguous sequences. A common pattern in sessionization and event stream processing. |

### 3. Concurrency & Parallelism

| Problem | Title & Link | Key Concepts |
|:--------|:-------------|:-------------|
| **1114** | [Print in Order](https://leetcode.com/problems/print-in-order/) | Mutex, Condition Variables |
| **1115** | [Print FooBar Alternately](https://leetcode.com/problems/print-foobar-alternately/) | Semaphores. Control interleaved execution of two threads. |
| **1188** | [Design Bounded Blocking Queue](https://leetcode.com/problems/design-bounded-blocking-queue/) | Producer-Consumer pattern, Mutex, Condition Variables |
| **1226** | [The Dining Philosophers](https://leetcode.com/problems/the-dining-philosophers/) | Deadlock prevention, Resource hierarchy |

| Problem Name | LeetCode # | Difficulty | Key Concepts | Relevance to Your Goals | Link |
|-------------|------------|------------|--------------|------------------------|------|
| **Fizz Buzz Multithreaded** | #1195 | ğŸŸ  Medium | Synchronization | Concurrent output coordination | [ğŸ”—](https://leetcode.com/problems/fizz-buzz-multithreaded/) |
| **Web Crawler Multithreaded** | #1242 | ğŸŸ  Medium | Concurrent BFS, Thread pools | Distributed web scraping patterns | [ğŸ”—](https://leetcode.com/problems/web-crawler-multithreaded/) |


#### 4. Advanced System Design Problems

| Problem Name | LeetCode # | Difficulty | Key Concepts | Relevance to Your Goals | Link |
|-------------|------------|------------|--------------|------------------------|------|
| **Design Twitter** | #355 | ğŸŸ  Medium | Social Graph, Feed System | Large-scale system design | [ğŸ”—](https://leetcode.com/problems/design-twitter/) |
| **Design Hit Counter** | #362 | ğŸŸ  Medium | Real-time Metrics, Time Windows | Monitoring and analytics | [ğŸ”—](https://leetcode.com/problems/design-hit-counter/) |
| **Serialize and Deserialize Binary Tree** | #297 | ğŸ”´ Hard | Data Serialization | Distributed data formats | [ğŸ”—](https://leetcode.com/problems/serialize-and-deserialize-binary-tree/) |
| **Insert Delete GetRandom O(1)** | #380 | ğŸŸ  Medium | Hash Map, Array, Random Access | Database indexing patterns | [ğŸ”—](https://leetcode.com/problems/insert-delete-getrandom-o1/) |

### Problem Set Statistics

| Category | Count | Easy | Medium | Hard | Focus Areas |
|----------|-------|------|--------|------|-------------|
| **System Design** | 8 | 0 | 5 | 3 | Caching, APIs, Data Structures |
| **Concurrency** | 4 | 1 | 3 | 0 | Parallelism, Synchronization |
| **Data Engineering** | 6 | 0 | 4 | 2 | SQL, Window Functions, Analytics |
| **Algorithms** | 8 | 0 | 4 | 4 | DP, Graphs, String Processing |
| **Total** | **26** | **1** | **16** | **9** | **Comprehensive Coverage** |

---

## System Design & Engineering

### Mini-Project: High-Performance LRU Cache

**Location**: `src/core/cpp/containers/lru_cache/include/lru_cache.h`

```cpp
#ifndef ALGORITHMIC_ENGINEERING_LRU_CACHE_H
#define ALGORITHMIC_ENGINEERING_LRU_CACHE_H

#include <unordered_map>
#include <list>
#include <mutex>

namespace core {
    
template <typename K, typename V>
class LRUCache {
public:
    explicit LRUCache(size_t capacity);
    
    // Core API
    bool get(const K& key, V& value);
    void put(const K& key, const V& value);
    
    // Observability
    size_t size() const;
    double hit_rate() const;

private:
    void evict();
    
    size_t capacity_;
    std::list<std::pair<K, V>> items_;
    std::unordered_map<K, typename std::list<std::pair<K, V>>::iterator> cache_map_;
    
    std::atomic<size_t> hits_{0};
    std::atomic<size_t> misses_{0};
    mutable std::mutex mutex_;
};

} // namespace core

#endif
```

### System Design: DataCody Agent

**Problem:** Design an intelligent agent ("DataCody") that can profile datasets, suggest quality checks, and recommend suitable ML models.

**Key Discussion Points:**
1.  **Service Architecture:** Microservices vs Monolith. API design (REST/gRPC).
2.  **Data Ingestion & Profiling:** Handling large datasets with Spark for distributed profiling.
3.  **Metadata Storage:** PostgreSQL for structured metadata, Neo4j for data lineage.
4.  **Model Recommendation Engine:** ML service that takes dataset stats and suggests model types.
5.  **Pipeline Integration:** CI/CD pipeline triggers via webhooks.

---

### **Interview Preparation & Notes**

#### **Coding Interview Guide**
*   **Clarify:** Ask questions. (Constraints, input/output format, edge cases).
*   **Example:** Walk through a small example to validate understanding.
*   **Brute Force:** State the naive solution and its complexity.
*   **Optimize:** Discuss better approaches (BUD: Bottlenecks, Unnecessary work, Duplicate work). Use known patterns.
*   **Implement:** Write clean, modular code. Use meaningful variable names.
*   **Test:** Walk through your code with the initial example and edge cases.

#### **Language-Specific Notes**
*   **C++:** Know the STL inside out (`vector`, `map`, `unordered_map`, `set`, `priority_queue`). Understand object lifecycle, rule of three/five, move semantics, and smart pointers.
*   **Python:** Understand the GIL, list comprehensions, generators, decorators, and the `collections` module (`defaultdict`, `Counter`, `deque`).

#### **Behavioral Questions (Using the STAR Method)**
*   Prepare stories for: "A challenging technical project," "A time you had a conflict," "How you handled a tight deadline."
*   Relate answers back to your projects and the skills required for `AI Infra` and `Data Systems`.

---

### **How to Use This Repository**
1.  **Fork this template** to your own GitHub.
2.  **Solve Problems Systematically:** For each problem, create a file in the appropriate `src/solutions/` directory.
3.  **Write Tests:** Always write corresponding unit tests in the `tests/` directory. This demonstrates professional coding habits.
4.  **Document:** Add a comment at the top of each solution file with the problem description, approach, and time/space complexity.
5.  **Iterate on Design:** Use the `system_design/` folder to draft and refine your answers to system design questions.


## Progress & Metrics

*   **`progress/solved_log.csv`:** Auto-generated progress tracking
    ```csv
    date,problem_id,title,difficulty,language,time_taken_minutes,notes
    2024-11-26,146,LRU Cache,Hard,C++,45,Implement thread-safe version
    ```
*   **`progress/roadmap_90_days.md`:** Phased learning plan
*   **`progress/retrospective.md`:** Lessons learned and improvements

---

## Getting Started

1.  **Clone and Setup:**
    ```bash
    git clone git@github.com:ArlesZhang/LeetCode-Solutions-Interview-Prep.git
    cd LeetCode-Solutions-Interview-Prep
    ```

2.  **Solve Problems Systematically:**
    ```bash
    # Create solution file
    vim src/solutions/cpp/0001-two-sum.cpp
    
    # Write tests
    vim tests/cpp/test_solutions.cpp
    
    # Update progress
    python scripts/generate_stats.py
    ```

3.  **Run Tests:**
    ```bash
    ./scripts/run_tests.sh cpp
    ./scripts/run_tests.sh python
    ```

4.  **Commit and Push:**
    ```bash
    git add .
    git commit -m "feat: solve PROBLEM_ID with APPROACH"
    git push origin main
    ```

---

<div align="center">

**This is more than a study guideâ€”it's the foundation of your engineering legacy. Build, learn, and iterate.**

</div>


